{
    "project name": "apache_vxquery",
    "modules": {
        "org.apache.vxquery:apache-vxquery": {
            "vulnerable dependencies": {
                "com.thoughtworks.xstream:xstream:1.3.1": {
                    "used-method num": 41,
                    "used method": [
                        "com.thoughtworks.xstream.converters.collections.TreeSetConverter$PresortedSet:boolean contains(java.lang.Object)",
                        "com.thoughtworks.xstream.core.util.PrioritizedList$PrioritizedItemIterator:boolean hasNext()",
                        "com.thoughtworks.xstream.core.util.CustomObjectOutputStream:void writeShort(int)",
                        "com.thoughtworks.xstream.XStream:void <init>(com.thoughtworks.xstream.io.HierarchicalStreamDriver)",
                        "com.thoughtworks.xstream.core.util.CustomObjectInputStream:void close()",
                        "com.thoughtworks.xstream.io.path.Path:java.lang.String toString()",
                        "com.thoughtworks.xstream.converters.collections.TreeSetConverter$PresortedSet:boolean add(java.lang.Object)",
                        "com.thoughtworks.xstream.converters.reflection.FieldKey:java.lang.String toString()",
                        "com.thoughtworks.xstream.core.util.ObjectIdDictionary$WeakIdWrapper:java.lang.String toString()",
                        "com.thoughtworks.xstream.XStream:java.lang.String toXML(java.lang.Object)",
                        "com.thoughtworks.xstream.core.util.XmlHeaderAwareReader:int read(char[],int,int)",
                        "com.thoughtworks.xstream.core.util.ObjectIdDictionary$IdWrapper:java.lang.String toString()",
                        "com.thoughtworks.xstream.core.util.PrioritizedList$PrioritizedItemIterator:java.lang.Object next()",
                        "com.thoughtworks.xstream.converters.collections.TreeMapConverter$PresortedMap:java.util.Set keySet()",
                        "com.thoughtworks.xstream.core.util.FastField:java.lang.String toString()",
                        "com.thoughtworks.xstream.converters.ConversionException:java.lang.String getMessage()",
                        "com.thoughtworks.xstream.core.util.CustomObjectOutputStream:void write(int)",
                        "com.thoughtworks.xstream.converters.collections.TreeMapConverter$PresortedMap:java.lang.Object put(java.lang.Object,java.lang.Object)",
                        "com.thoughtworks.xstream.core.util.XmlHeaderAwareReader:void close()",
                        "com.thoughtworks.xstream.core.util.CustomObjectOutputStream:void writeFloat(float)",
                        "com.thoughtworks.xstream.core.util.OrderRetainingMap:java.lang.Object put(java.lang.Object,java.lang.Object)",
                        "com.thoughtworks.xstream.converters.collections.TreeMapConverter$PresortedMap:void clear()",
                        "com.thoughtworks.xstream.core.util.XmlHeaderAwareReader:java.lang.String toString()",
                        "com.thoughtworks.xstream.io.json.JsonHierarchicalStreamDriver:void <init>()",
                        "com.thoughtworks.xstream.converters.collections.TreeMapConverter$PresortedMap:java.util.Collection values()",
                        "com.thoughtworks.xstream.converters.collections.TreeSetConverter$PresortedSet:java.util.Iterator iterator()",
                        "com.thoughtworks.xstream.core.util.CustomObjectOutputStream:void writeLong(long)",
                        "com.thoughtworks.xstream.core.util.CustomObjectOutputStream:void writeByte(int)",
                        "com.thoughtworks.xstream.core.util.OrderRetainingMap:java.util.Collection values()",
                        "com.thoughtworks.xstream.core.util.OrderRetainingMap:java.lang.Object remove(java.lang.Object)",
                        "com.thoughtworks.xstream.converters.collections.TreeMapConverter$PresortedMap:int size()",
                        "com.thoughtworks.xstream.core.util.OrderRetainingMap:java.util.Set entrySet()",
                        "com.thoughtworks.xstream.core.util.CustomObjectOutputStream:void writeDouble(double)",
                        "com.thoughtworks.xstream.core.util.CustomObjectOutputStream:void write(byte[])",
                        "com.thoughtworks.xstream.io.xml.DomDriver:void <init>()",
                        "com.thoughtworks.xstream.core.util.CustomObjectOutputStream:void write(byte[],int,int)",
                        "com.thoughtworks.xstream.core.util.CustomObjectOutputStream:void writeInt(int)",
                        "com.thoughtworks.xstream.converters.collections.TreeSetConverter$PresortedSet:int size()",
                        "com.thoughtworks.xstream.core.util.OrderRetainingMap:java.util.Set keySet()",
                        "com.thoughtworks.xstream.core.util.FastStack:java.lang.String toString()",
                        "com.thoughtworks.xstream.converters.collections.TreeMapConverter$PresortedMap:java.lang.Object get(java.lang.Object)"
                    ],
                    "CVE": [
                        "CVE-2017-7957"
                    ],
                    "used vul-method": [
                        "com.thoughtworks.xstream.XStream:void <init>(com.thoughtworks.xstream.io.HierarchicalStreamDriver)"
                    ],
                    "vul-called frequency": 2,
                    "related vul root method": {
                        "CVE-2017-7957": [
                            "com.thoughtworks.xstream.XStream:void setupConverters()"
                        ]
                    },
                    "CVE-API": {
                        "CVE-2017-7957": [
                            "com.thoughtworks.xstream.XStream:void <init>(com.thoughtworks.xstream.io.HierarchicalStreamDriver)"
                        ]
                    }
                },
                "junit:junit:4.11": {
                    "used-method num": 0,
                    "used method": []
                },
                "org.apache.hadoop:hadoop-common:2.7.0": {
                    "used-method num": 112,
                    "used method": [
                        "org.apache.hadoop.fs.permission.AclStatus:java.lang.String toString()",
                        "org.apache.hadoop.util.ReflectionUtils:java.lang.Object newInstance(java.lang.Class,org.apache.hadoop.conf.Configuration)",
                        "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker:void close()",
                        "org.apache.hadoop.util.Shell$ShellCommandExecutor:java.lang.String toString()",
                        "org.apache.hadoop.conf.Configuration:java.lang.String get(java.lang.String)",
                        "org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl:java.lang.String toString()",
                        "org.apache.hadoop.io.Text:void set(byte[],int,int)",
                        "org.apache.hadoop.util.ReflectionUtils:void <clinit>()",
                        "org.apache.hadoop.io.DataOutputBuffer:void <init>()",
                        "org.apache.hadoop.io.retry.RetryPolicy$RetryAction:java.lang.String toString()",
                        "org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext$PathIterator:org.apache.hadoop.fs.Path next()",
                        "org.apache.hadoop.metrics2.lib.MetricsRegistry:java.lang.String toString()",
                        "org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolSignatureProto$Builder:org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolSignatureProto$Builder clone()",
                        "org.apache.hadoop.fs.ContentSummary:java.lang.String toString()",
                        "org.apache.hadoop.ipc.RemoteException:java.lang.String toString()",
                        "org.apache.hadoop.conf.Configuration:void set(java.lang.String,java.lang.String)",
                        "org.apache.hadoop.fs.FileSystem:org.apache.hadoop.fs.RemoteIterator listFiles(org.apache.hadoop.fs.Path,boolean)",
                        "org.apache.hadoop.fs.FSDataInputStream:java.io.InputStream getWrappedStream()",
                        "org.apache.hadoop.conf.Configuration:void <init>()",
                        "org.apache.hadoop.fs.FileStatus:org.apache.hadoop.fs.Path getPath()",
                        "org.apache.hadoop.fs.FileSystem:org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)",
                        "org.apache.hadoop.metrics2.MetricsTag:java.lang.String toString()",
                        "org.apache.hadoop.util.Progress:java.lang.String toString()",
                        "org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolVersionsRequestProto$Builder:org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolVersionsRequestProto$Builder clone()",
                        "org.apache.hadoop.fs.FileStatus:long getLen()",
                        "org.apache.hadoop.metrics2.util.SampleQuantiles:java.lang.String toString()",
                        "org.apache.hadoop.security.authorize.AccessControlList:java.lang.String toString()",
                        "org.apache.hadoop.ipc.Server$Call:java.lang.String toString()",
                        "org.apache.hadoop.ipc.Server$Connection:java.lang.String toString()",
                        "org.apache.hadoop.fs.RawLocalFileSystem:boolean delete(org.apache.hadoop.fs.Path,boolean)",
                        "org.apache.hadoop.io.LongWritable:java.lang.String toString()",
                        "org.apache.hadoop.io.BytesWritable:java.lang.String toString()",
                        "org.apache.hadoop.fs.FileSystem$Statistics$StatisticsData:java.lang.String toString()",
                        "org.apache.hadoop.fs.FSDataInputStream:void seek(long)",
                        "org.apache.hadoop.fs.Options$ChecksumOpt:java.lang.String toString()",
                        "org.apache.hadoop.fs.Path:void <clinit>()",
                        "org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolSignatureRequestProto$Builder:org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolSignatureRequestProto$Builder clone()",
                        "org.apache.hadoop.ipc.Client$ConnectionId:java.lang.String toString()",
                        "org.apache.hadoop.net.NodeBase:java.lang.String toString()",
                        "org.apache.hadoop.fs.Path:java.lang.String getName()",
                        "org.apache.hadoop.fs.FileSystem:void copyFromLocalFile(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)",
                        "org.apache.hadoop.metrics2.util.Quantile:java.lang.String toString()",
                        "org.apache.hadoop.fs.FileSystem:org.apache.hadoop.fs.BlockLocation[] getFileBlockLocations(org.apache.hadoop.fs.FileStatus,long,long)",
                        "org.apache.hadoop.fs.Path:org.apache.hadoop.fs.FileSystem getFileSystem(org.apache.hadoop.conf.Configuration)",
                        "org.apache.hadoop.security.UserGroupInformation:java.lang.String toString()",
                        "org.apache.hadoop.io.LongWritable:void <clinit>()",
                        "org.apache.hadoop.metrics2.impl.MsInfo:java.lang.String toString()",
                        "org.apache.hadoop.io.DataOutputBuffer:org.apache.hadoop.io.DataOutputBuffer reset()",
                        "org.apache.hadoop.util.DataChecksum:java.lang.String toString()",
                        "org.apache.hadoop.conf.Configuration:void addResource(org.apache.hadoop.fs.Path)",
                        "org.apache.hadoop.fs.Path:java.lang.String toString()",
                        "org.apache.hadoop.io.retry.RetryPolicies$MultipleLinearRandomRetry$Pair:java.lang.String toString()",
                        "org.apache.hadoop.io.DataOutputBuffer:byte[] getData()",
                        "org.apache.hadoop.fs.FileStatus:java.lang.String toString()",
                        "org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolVersionsResponseProto$Builder:org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolVersionsResponseProto$Builder clone()",
                        "org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder:org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder clone()",
                        "org.apache.hadoop.io.Text:void <init>()",
                        "org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolVersionProto$Builder:org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolVersionProto$Builder clone()",
                        "org.apache.hadoop.security.UserGroupInformation$RealUser:java.lang.String toString()",
                        "org.apache.hadoop.io.retry.RetryPolicies$RetryLimited:java.lang.String toString()",
                        "org.apache.hadoop.fs.FileContext$Util$2:boolean hasNext()",
                        "org.apache.hadoop.conf.Configuration:java.lang.String toString()",
                        "org.apache.hadoop.io.LongWritable:void <init>()",
                        "org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCTraceInfoProto$Builder:org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCTraceInfoProto$Builder clone()",
                        "org.apache.hadoop.fs.FileSystem:boolean isDirectory(org.apache.hadoop.fs.Path)",
                        "org.apache.hadoop.conf.Configuration$IntegerRanges:java.lang.String toString()",
                        "org.apache.hadoop.fs.FileSystem$Cache$Key:java.lang.String toString()",
                        "org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$Builder:org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$Builder clone()",
                        "org.apache.hadoop.conf.Configuration:void <clinit>()",
                        "org.apache.hadoop.io.NullWritable:java.lang.String toString()",
                        "org.apache.hadoop.io.compress.CompressionCodecFactory:java.lang.String toString()",
                        "org.apache.hadoop.ipc.Server$WrappedRpcServerException:java.lang.String toString()",
                        "org.apache.hadoop.fs.permission.AclEntry:java.lang.String toString()",
                        "org.apache.hadoop.fs.RawLocalFileSystem:void close()",
                        "org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$UserInformationProto$Builder:org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$UserInformationProto$Builder clone()",
                        "org.apache.hadoop.fs.FileSystem:org.apache.hadoop.fs.FSDataInputStream open(org.apache.hadoop.fs.Path)",
                        "org.apache.hadoop.fs.FSDataInputStream:long getPos()",
                        "org.apache.hadoop.fs.DF:java.lang.String toString()",
                        "org.apache.hadoop.fs.FileSystem:void <clinit>()",
                        "org.apache.hadoop.crypto.CryptoInputStream:void close()",
                        "org.apache.hadoop.io.VersionMismatchException:java.lang.String toString()",
                        "org.apache.hadoop.fs.RawLocalFileSystem:org.apache.hadoop.fs.FileStatus getFileStatus(org.apache.hadoop.fs.Path)",
                        "org.apache.hadoop.io.SequenceFile$Metadata:java.lang.String toString()",
                        "org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder:org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder clone()",
                        "org.apache.hadoop.metrics2.util.SampleQuantiles$SampleItem:java.lang.String toString()",
                        "org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$IpcConnectionContextProto$Builder:org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$IpcConnectionContextProto$Builder clone()",
                        "org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto$Builder:org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto$Builder clone()",
                        "org.apache.hadoop.security.token.Token:java.lang.String toString()",
                        "org.apache.hadoop.conf.Configuration$IntegerRanges$RangeNumberIterator:java.lang.Integer next()",
                        "org.apache.hadoop.fs.RawLocalFileSystem:org.apache.hadoop.fs.Path getHomeDirectory()",
                        "org.apache.hadoop.io.LongWritable:void set(long)",
                        "org.apache.hadoop.io.UTF8:java.lang.String toString()",
                        "org.apache.hadoop.io.DataOutputBuffer:int getLength()",
                        "org.apache.hadoop.io.nativeio.NativeIOException:java.lang.String toString()",
                        "org.apache.hadoop.net.SocketInputStream:void close()",
                        "org.apache.hadoop.crypto.CipherSuite:java.lang.String toString()",
                        "org.apache.hadoop.io.Text:void <clinit>()",
                        "org.apache.hadoop.io.Text:java.lang.String toString()",
                        "org.apache.hadoop.ipc.protobuf.ProtobufRpcEngineProtos$RequestHeaderProto$Builder:org.apache.hadoop.ipc.protobuf.ProtobufRpcEngineProtos$RequestHeaderProto$Builder clone()",
                        "org.apache.hadoop.io.retry.RetryPolicies$MultipleLinearRandomRetry:java.lang.String toString()",
                        "org.apache.hadoop.io.IntWritable:java.lang.String toString()",
                        "org.apache.hadoop.metrics2.impl.MetricsConfig:java.lang.String toString()",
                        "org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream:void close()",
                        "org.apache.hadoop.fs.Path:void <init>(java.lang.String)",
                        "org.apache.hadoop.fs.FileSystem:boolean exists(org.apache.hadoop.fs.Path)",
                        "org.apache.hadoop.security.User:java.lang.String toString()",
                        "org.apache.hadoop.fs.permission.FsPermission:java.lang.String toString()",
                        "org.apache.hadoop.fs.FileContext$Util$2:org.apache.hadoop.fs.LocatedFileStatus next()",
                        "org.apache.hadoop.conf.Configuration$IntegerRanges$RangeNumberIterator:boolean hasNext()",
                        "org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolSignatureResponseProto$Builder:org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolSignatureResponseProto$Builder clone()",
                        "org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper:java.lang.String toString()",
                        "org.apache.hadoop.io.compress.DecompressorStream:void close()"
                    ]
                },
                "org.apache.hadoop:hadoop-mapreduce-client-core:2.7.0": {
                    "used-method num": 51,
                    "used method": [
                        "org.apache.hadoop.mapreduce.Job:java.lang.String toString()",
                        "org.apache.hadoop.mapreduce.task.reduce.MapOutput:java.lang.String toString()",
                        "org.apache.hadoop.mapreduce.QueueState:java.lang.String toString()",
                        "org.apache.hadoop.mapreduce.task.JobContextImpl:java.lang.Class getInputFormatClass()",
                        "org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo:java.lang.String toString()",
                        "org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader:java.lang.Object getCurrentValue()",
                        "org.apache.hadoop.mapred.ReduceTask$ReduceValuesIterator:java.lang.Object next()",
                        "org.apache.hadoop.mapred.Task$CombineValuesIterator:boolean hasNext()",
                        "org.apache.hadoop.mapreduce.lib.input.TextInputFormat:void <init>()",
                        "org.apache.hadoop.mapreduce.TaskID:java.lang.String toString()",
                        "org.apache.hadoop.mapreduce.lib.input.LineRecordReader:org.apache.hadoop.io.Text getCurrentValue()",
                        "org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context:org.apache.hadoop.conf.Configuration getConfiguration()",
                        "org.apache.hadoop.mapreduce.lib.input.FileSplit:java.lang.String toString()",
                        "org.apache.hadoop.mapred.Task:java.lang.String toString()",
                        "org.apache.hadoop.mapreduce.lib.input.FileSplit:long getLength()",
                        "org.apache.hadoop.mapred.IFileInputStream:void close()",
                        "org.apache.hadoop.mapreduce.JobStatus:java.lang.Object clone()",
                        "org.apache.hadoop.mapreduce.TaskAttemptID:java.lang.String toString()",
                        "org.apache.hadoop.mapred.SortedRanges$SkipRangeIterator:java.lang.Long next()",
                        "org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper$KeyDescription:java.lang.String toString()",
                        "org.apache.hadoop.mapreduce.Job:void setInputFormatClass(java.lang.Class)",
                        "org.apache.hadoop.mapred.Task$ValuesIterator:boolean hasNext()",
                        "org.apache.hadoop.mapreduce.task.JobContextImpl:org.apache.hadoop.conf.Configuration getConfiguration()",
                        "org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterator:boolean hasNext()",
                        "org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader:void close()",
                        "org.apache.hadoop.mapred.Task$CombineValuesIterator:java.lang.Object next()",
                        "org.apache.hadoop.mapred.SortedRanges$Range:java.lang.String toString()",
                        "org.apache.hadoop.mapreduce.lib.input.InvalidInputException:java.lang.String getMessage()",
                        "org.apache.hadoop.mapreduce.lib.input.FileInputFormat:void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)",
                        "org.apache.hadoop.mapreduce.lib.input.LineRecordReader:boolean nextKeyValue()",
                        "org.apache.hadoop.mapreduce.lib.input.FileSplit:org.apache.hadoop.mapred.SplitLocationInfo[] getLocationInfo()",
                        "org.apache.hadoop.mapreduce.lib.input.FileInputFormat:void <clinit>()",
                        "org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader:boolean nextKeyValue()",
                        "org.apache.hadoop.mapreduce.lib.input.FileSplit:long getStart()",
                        "org.apache.hadoop.mapreduce.JobID:java.lang.String toString()",
                        "org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context:org.apache.hadoop.conf.Configuration getConfiguration()",
                        "org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader:void initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)",
                        "org.apache.hadoop.mapreduce.lib.input.FileSplit:org.apache.hadoop.fs.Path getPath()",
                        "org.apache.hadoop.mapreduce.Job:void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)",
                        "org.apache.hadoop.mapreduce.JobStatus:java.lang.String toString()",
                        "org.apache.hadoop.mapred.InvalidInputException:java.lang.String getMessage()",
                        "org.apache.hadoop.mapreduce.lib.input.LineRecordReader:void close()",
                        "org.apache.hadoop.mapreduce.Job:void <clinit>()",
                        "org.apache.hadoop.mapreduce.RecordReader:void <init>()",
                        "org.apache.hadoop.mapred.JVMId:java.lang.String toString()",
                        "org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterator:java.lang.Object next()",
                        "org.apache.hadoop.mapreduce.lib.input.LineRecordReader:void initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)",
                        "org.apache.hadoop.mapreduce.TaskCompletionEvent:java.lang.String toString()",
                        "org.apache.hadoop.mapred.SortedRanges$SkipRangeIterator:boolean hasNext()",
                        "org.apache.hadoop.mapreduce.counters.AbstractCounters:java.lang.String toString()",
                        "org.apache.hadoop.mapred.Queue:java.lang.String toString()"
                    ],
                    "CVE": [
                        "CVE-2015-1776"
                    ],
                    "used vul-method": [
                        "org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterator:java.lang.Object next()"
                    ],
                    "vul-called frequency": 136,
                    "related vul root method": {
                        "CVE-2015-1776": [
                            "org.apache.hadoop.mapreduce.CryptoUtils:byte[] getEncryptionKey()"
                        ]
                    },
                    "CVE-API": {
                        "CVE-2015-1776": [
                            "org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterator:java.lang.Object next()"
                        ]
                    }
                }
            }
        }
    }
}