{
    "project name": "yahoo_storm-yarn",
    "vulnerable dependencies": {
        "org.apache.hadoop:hadoop-common:2.8.2": {
            "used-method num": 99,
            "used method": [
                "org.apache.hadoop.service.AbstractService:void stop()",
                "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker:void close()",
                "org.apache.hadoop.fs.FSDataOutputStream$PositionCache:void write(int)",
                "org.apache.hadoop.net.NetUtils:void <clinit>()",
                "org.apache.hadoop.fs.GlobalStorageStatistics$StorageIterator:org.apache.hadoop.fs.StorageStatistics next()",
                "org.apache.hadoop.net.SocketOutputStream:void write(int)",
                "org.apache.hadoop.util.Shell$1:void run()",
                "org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext$PathIterator:void remove()",
                "org.apache.hadoop.fs.GlobalStorageStatistics$StorageIterator:void remove()",
                "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker:int available()",
                "org.apache.hadoop.security.UserGroupInformation:void <clinit>()",
                "org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream:int read()",
                "org.apache.hadoop.io.DataOutputBuffer:void <init>()",
                "org.apache.hadoop.fs.FileSystem:void copyFromLocalFile(boolean,boolean,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)",
                "org.apache.hadoop.io.compress.DecompressorStream:int read()",
                "org.apache.hadoop.io.DataOutputBuffer:byte[] getData()",
                "org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext$PathIterator:org.apache.hadoop.fs.Path next()",
                "org.ietf.jgss.GSSException:java.lang.String getMessage()",
                "org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolVersionsResponseProto$Builder:org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolVersionsResponseProto$Builder clone()",
                "org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder:org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth$Builder clone()",
                "org.apache.hadoop.ipc.Server$Handler:void run()",
                "org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolVersionProto$Builder:org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolVersionProto$Builder clone()",
                "org.apache.hadoop.fs.FileSystemStorageStatistics$LongStatisticIterator:boolean hasNext()",
                "org.apache.hadoop.fs.FileStatus:long getModificationTime()",
                "org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolSignatureProto$Builder:org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolSignatureProto$Builder clone()",
                "org.apache.hadoop.crypto.CryptoOutputStream:void write(int)",
                "org.apache.hadoop.fs.permission.FsAction:void <clinit>()",
                "org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCTraceInfoProto$Builder:org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCTraceInfoProto$Builder clone()",
                "org.apache.hadoop.io.BoundedByteArrayOutputStream:void write(int)",
                "org.apache.hadoop.security.Credentials:void <clinit>()",
                "org.apache.hadoop.ipc.Client$Connection$PingInputStream:int read()",
                "org.apache.hadoop.security.Credentials:void writeTokenStorageToStream(java.io.DataOutputStream)",
                "org.apache.hadoop.ipc.Server$Listener:void run()",
                "org.apache.hadoop.ipc.Server$Responder:void run()",
                "org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$Builder:org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$Builder clone()",
                "org.apache.hadoop.net.NetUtils:java.net.InetSocketAddress createSocketAddr(java.lang.String)",
                "org.apache.hadoop.net.SocketInputStream:int read()",
                "org.apache.hadoop.service.AbstractService:void <clinit>()",
                "org.apache.hadoop.fs.RawLocalFileSystem:boolean mkdirs(org.apache.hadoop.fs.Path)",
                "org.apache.hadoop.fs.FileSystemStorageStatistics$LongStatisticIterator:void remove()",
                "org.apache.hadoop.fs.FileSystem:org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)",
                "org.apache.hadoop.security.UserGroupInformation:java.lang.String getShortUserName()",
                "org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCCallerContextProto$Builder:org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RPCCallerContextProto$Builder clone()",
                "org.apache.hadoop.fs.permission.FsAction:boolean implies(org.apache.hadoop.fs.permission.FsAction)",
                "org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$UserInformationProto$Builder:org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$UserInformationProto$Builder clone()",
                "org.apache.hadoop.security.SaslRpcClient$WrappedInputStream:int read()",
                "org.apache.hadoop.fs.FileSystem:org.apache.hadoop.fs.FSDataInputStream open(org.apache.hadoop.fs.Path)",
                "org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolVersionsRequestProto$Builder:org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolVersionsRequestProto$Builder clone()",
                "org.apache.hadoop.fs.FileStatus:long getLen()",
                "org.apache.hadoop.security.Credentials:void <init>()",
                "org.apache.hadoop.ipc.Client$Connection:void run()",
                "org.apache.hadoop.fs.FileSystem:void <clinit>()",
                "org.apache.hadoop.fs.FileSystemStorageStatistics$LongStatisticIterator:org.apache.hadoop.fs.StorageStatistics$LongStatistic next()",
                "org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream:void write(int)",
                "org.apache.hadoop.crypto.CryptoInputStream:void close()",
                "org.apache.hadoop.fs.RawLocalFileSystem:org.apache.hadoop.fs.FileStatus getFileStatus(org.apache.hadoop.fs.Path)",
                "org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder:org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$Builder clone()",
                "org.apache.hadoop.io.compress.DecompressorStream:int available()",
                "org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$IpcConnectionContextProto$Builder:org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$IpcConnectionContextProto$Builder clone()",
                "org.apache.hadoop.fs.Path:org.apache.hadoop.fs.Path makeQualified(org.apache.hadoop.fs.FileSystem)",
                "org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto$Builder:org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto$Builder clone()",
                "org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus:org.apache.hadoop.fs.permission.FsPermission getPermission()",
                "org.apache.hadoop.conf.Configuration$IntegerRanges$RangeNumberIterator:java.lang.Integer next()",
                "org.apache.hadoop.fs.FileSystem:org.apache.hadoop.fs.FSDataOutputStream create(org.apache.hadoop.fs.Path)",
                "org.apache.hadoop.util.ShutdownHookManager$1:void run()",
                "org.apache.hadoop.fs.RawLocalFileSystem:org.apache.hadoop.fs.Path getHomeDirectory()",
                "org.apache.hadoop.io.DataOutputBuffer:int getLength()",
                "org.apache.hadoop.net.SocketInputStream:void close()",
                "org.apache.hadoop.service.AbstractService:void init(org.apache.hadoop.conf.Configuration)",
                "org.apache.hadoop.fs.FileSystem:org.apache.hadoop.fs.Path makeQualified(org.apache.hadoop.fs.Path)",
                "org.apache.hadoop.fs.FileStatus:org.apache.hadoop.fs.permission.FsPermission getPermission()",
                "org.apache.hadoop.security.UserGroupInformation:org.apache.hadoop.security.Credentials getCredentials()",
                "org.apache.hadoop.fs.Path:java.net.URI toUri()",
                "org.apache.hadoop.fs.FSDataOutputStream:void close()",
                "org.apache.hadoop.crypto.CryptoInputStream:int read()",
                "org.apache.hadoop.conf.Configuration$IntegerRanges$RangeNumberIterator:void remove()",
                "org.apache.hadoop.util.LimitInputStream:int available()",
                "org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream:void close()",
                "org.apache.hadoop.fs.Path:void <clinit>()",
                "org.apache.hadoop.fs.Path:void <init>(java.lang.String)",
                "org.apache.hadoop.io.compress.GzipCodec$GzipOutputStream:void write(int)",
                "org.apache.hadoop.fs.FSInputChecker:int read()",
                "org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolSignatureRequestProto$Builder:org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolSignatureRequestProto$Builder clone()",
                "org.apache.hadoop.crypto.CryptoInputStream:int available()",
                "org.apache.hadoop.ipc.Server$Listener$Reader:void run()",
                "org.apache.hadoop.io.DataInputByteBuffer$Buffer:int read()",
                "org.apache.hadoop.fs.Path:void <init>(org.apache.hadoop.fs.Path,java.lang.String)",
                "org.apache.hadoop.service.AbstractService:void start()",
                "org.apache.hadoop.service.Service$STATE:void <clinit>()",
                "org.apache.hadoop.conf.Configuration$IntegerRanges$RangeNumberIterator:boolean hasNext()",
                "org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream:int available()",
                "org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolSignatureResponseProto$Builder:org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolSignatureResponseProto$Builder clone()",
                "org.apache.hadoop.security.UserGroupInformation:org.apache.hadoop.security.UserGroupInformation getCurrentUser()",
                "org.apache.hadoop.io.compress.DecompressorStream:void close()",
                "org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1:void run()",
                "org.apache.hadoop.service.AbstractService:org.apache.hadoop.service.Service$STATE getServiceState()",
                "org.apache.hadoop.fs.Path:org.apache.hadoop.fs.Path getParent()",
                "org.apache.hadoop.fs.permission.FsPermission:org.apache.hadoop.fs.permission.FsAction getOtherAction()",
                "org.apache.hadoop.io.compress.CompressorStream:void write(int)"
            ]
        }
    }
}